---
title: "Práctica Sesión 9"
author: 
  - Mariana Lugo 
  - Mario Heredia
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# Modelación en Ciencia de Datos
## *Matching*

Para la elaboración de la práctica se utilizan las siguientes librerías: 

```{r, message=FALSE}
library(tidyverse)
library(haven)
library(MatchIt)
library(knitr)
```

Para el ejercicio se utilizan los datos del experimento del mercado laboral del *National Supported Work*. El programa consistía en proveer experiencia laboral aquellos individuos que habían efrentado problemas económicos y sociales previos a su registro en el programa. Los participantes del experiemento fueron separados en un grupo de tratamiento y uno de control. 

Por otro lado, se utilizan controles experiementales para obtener una estimación benchmark para el impacto del tratamiento uniendo a las unidades de tratamiento del experimento con la unidades de comparación de la *Population Survey of Income Dynamics (PSID)* y del *Current Population Survey (CPS)*.

Se cargan los datos que su utilizarán en la práctica y se contruye el set de datos utilizado en el paper. 

```{r}
cps <- read_dta("https://raw.github.com/scunning1975/mixtape/master/cps_mixtape.dta") 
psid <- read_dta("https://raw.github.com/scunning1975/mixtape/master/nsw_mixtape.dta")

nsw_dw_cpscontrol <- cps %>% 
  bind_rows(psid) %>% 
  mutate(agesq = age^2,
         agecube = age^3,
         educsq = educ^2,
         u74 = ifelse(re74 == 0,0,1),
         u75 = ifelse(re75 == 0,0,1),
         interaction1 = educ*re74
         )
```


### 1. Revise la descripción del programa que se realiza en la Sección I y replique la Tabla 1 de la muestra utilizada por los autores para describir a su conjunto de datos.

```{r}
tabla1 <- nsw_dw_cpscontrol %>% 
  filter(data_id == "Dehejia-Wahba Sample") %>% 
  select(-matches('sq|cube|interaction')) %>% 
  group_by(treat = factor(treat, levels = c(1,0))) %>% 
  summarise(across(where(is.numeric), mean),
            sample_size = n()) %>% 
   pivot_longer(names_to = 'variable', values_to = 'values', cols = -treat) %>% 
   pivot_wider(names_from = treat, values_from = values)

names(tabla1)[2]<-"Tratamiento"
  names(tabla1)[3]<-"Control"

kable(tabla1)
```

En la tabla 1 se muestra la media de todas la características de la muestra de datos utilizada para el análisis. Como se establecer en el paper, se muestra que el debido al selección aleatorio para el grupo de control y de tratamiento, no existen diferencias siginificativas de las variable entre los grupos. 

### 2. Calcule el ATE del experimento.   

Se obtiene que el efecto del NSW job-training program sobre los ingresos reales fue un incremento de $1,794.343. (renglón 1 de la tabla 2).

```{r}
ATE<-tabla1 %>% 
  filter(variable == 're78') %>% 
  summarise(ATE = Tratamiento-Control) 

kable(ATE)
```

Se compara el renglón del Full CPS de la tabla 2:

```{r}
Full_CPS <-nsw_dw_cpscontrol %>% 
  filter(data_id == "CPS1") %>% 
  select(-matches('sq|cube|interaction')) %>% 
  group_by(treat = factor(treat, levels = c(1,0))) %>% 
  summarise(across(where(is.numeric), mean),
            sample_size = n()) %>% 
  pivot_longer(names_to = 'variable', values_to = 'values', cols = -treat) %>% 
  pivot_wider(names_from = treat, values_from = values)%>%
  mutate(across(where(is.numeric), ~round(., 2))) %>% 
  data.frame()

names(Full_CPS)[2]<- "Full CPS"

kable(Full_CPS)

```


### 3. Siguiendo el procedimiento de los autores, ahora utilice la información de la encuesta CPS como grupo de control no experimental. Agregue este conjunto de datos a los datos experimentales y estime el propensity score usando un modelo logit.

* Se define el modelo: 

```{r}
## NSW vs CPS

psid_cov <- nsw_dw_cpscontrol %>% 
  select(age:re75, agesq:interaction1) %>% 
  names() 

(frml <- paste0(psid_cov, collapse = '+') %>% 
  paste('treat', ., sep = '~') %>% 
  as.formula()) 


logit_cps <- nsw_dw_cpscontrol %>% 
  filter(!(data_id == 'Dehejia-Wahba Sample' & treat == 0)) %>% #quitar los PSID, i.e. comparar NSW vs CPS
  glm(frml, family = binomial(link = 'logit'),
            data = .)
logit_cps %>% summary()
```
Se calcula el *propensity score*: 

```{r}
pr_df <- nsw_dw_cpscontrol %>% 
  filter(!(data_id == 'Dehejia-Wahba Sample' & treat == 0)) %>% #quitar los PSID, i.e. comparar NSW vs CPS
  mutate(pr_score = logit_cps$fitted.values)


ps<- pr_df %>% 
  group_by(data_id,treat) %>% 
  summarise(across(pr_score, mean)) 

kable(ps)

```


Los resultados del propensity score, coinciden con los resultados del libro. Se puede observar que la mediana del propensity score es 0.4.

```{r}
ps_percentil<-pr_df %>% 
  group_by(data_id) %>% 
  summarise(
    p01 = quantile(pr_score, 0.01),
    p05 = quantile(pr_score, 0.05),
    p10 = quantile(pr_score, 0.10),
    p25 = quantile(pr_score, 0.25),
    p50 = quantile(pr_score, 0.50),
    p75 = quantile(pr_score, 0.75),
    p90 = quantile(pr_score, 0.90),
    p95 = quantile(pr_score, 0.95),
    p99 = quantile(pr_score, 0.99)
    
    ) %>% 
  pivot_longer(names_to = 'percentiles', values_to = 'values', cols = -data_id) %>% 
  pivot_wider(names_from = data_id, values_from = values)

kable(ps_percentil)
```

### 4. Mediante la construcción del histograma para ambos grupos, analice la región del *commun support*.

```{r, warning=FALSE}
pr_df%>% 
  ggplot(aes(pr_score, after_stat(density)), fill= factor(treat)) +
  geom_histogram(binwidth = 0.02)+ #el valor del eje y cambia de acuerdo al valor de binwidth
  facet_wrap(~treat)+
  xlim(c(-0.1,1.02)) + xlab("Propensity Score")
```
Se puedo observar que para el intervalo del propensity score existen unidades en el grupo de tratamiento con un propensity score de mayor a 0.25, mientras que no se observan unidades en ese intervalo en el grupo de control. Es decir, en general no se muestra una superposición de los propensity scores de los grupos.  


```{r}
min_treated <- pr_df %>% 
  group_by(treat) %>% 
  summarise(min = min(pr_score)) %>% 
  filter(treat == 1) %>% 
  pull(min)

pr_df %>% 
   filter(pr_score >= min_treated) %>% ##excluimos 12136 con este filtro
  ggplot(aes(pr_score, after_stat(density), colour = factor(treat), group = factor(treat)))+
  geom_histogram(fill="white", position = "dodge",bins = 19, alpha = 0.95)+  guides(fill = guide_legend(title = "Grupo"),
         colour = guide_legend(title = "Grupo"))

```

En la gráfica anterior se muestra que filtrando el propepensity score mínimo del grupo de tratamiento, se observa un common support entre los grupos. Hay más sobreposición entre los grupos. 

###  5. Utilice el procedimiento de matching bajo los siguientes criterios para calcular el ATE, compare sus resultados y concluya el efecto del tratamiento en el contexto del problema.

Datos:

```{r}
new_dta <-nsw_dw_cpscontrol %>% 
  filter(!(data_id == 'Dehejia-Wahba Sample' & treat == 0)) 
```


#### a)  Weighting on the propensity score

```{r}
N <- nrow(pr_df)

penalty_df <- pr_df %>% 
  mutate(d1 = treat/pr_score, #0 cuando treat=0, grande cuando treat=1 y pr_score~0 (penaliza FN)
         d0 = (1-treat)/(1-pr_score)) #0 cuando treat=1, grande cuando treat=0 y pr_score~1 (penaliza FP)

# non-no}rmalized weights --------------------------------------------------

wt_df <- penalty_df %>% 
  mutate(y1 = d1*re78, #d1 * re78 (penalty de FN mult por el salario resultante)
         y0 = d0*re78, #d0 * re78
         ht = y1 - y0) #ATT

wt_df %>% 
  pull(ht) %>% 
  mean()

# Normalized weights ------------------------------------------------------

s1 <- sum(penalty_df$d1)
s0 <- sum(penalty_df$d0)

wt_norm_df <- penalty_df %>% 
  mutate(y1 = (d1*re78)/(s1/N),
         y0 = (d0*re78)/(s0/N),
         norm = y1 - y0)


wt_norm_df %>% 
  pull(norm) %>% 
  mean()

# trimming propensity score -----------------------------------------------

penalty_trimmed <- pr_df %>% 
  filter(between(pr_score, 0.1,0.9))%>% 
  mutate(d1 = treat/pr_score, #0 cuando treat=0, grande cuando treat=1 y pr_score~0 (penaliza FN)
         d0 = (1-treat)/(1-pr_score))

# Non normalized
wt_df_trimmed <- penalty_trimmed %>% 
  mutate(y1 = d1 * re78, #d1 * re78 (penalty de FN mult por el salario resultante)
         y0 = d0 *re78, #d0 * re78
         ht = y1 - y0)

wt_df_trimmed %>% 
  pull(ht) %>% 
  mean()

#Normalized

N_tr <- nrow(penalty_trimmed)
s1_tr <- sum(penalty_trimmed$d1)
s0_tr <- sum(penalty_trimmed$d0)

wt_norm_df_trimmed <- penalty_trimmed %>% 
  mutate(y1 = (d1*re78)/(s1_tr/N_tr),
         y0 = (d0*re78)/(s0_tr/N_tr),
         norm = y1 - y0)


wt_norm_df_trimmed %>% 
  pull(norm) %>% 
  mean()
```


#### b) Nearest-neighbor matching

```{r}
mod_match_nn <- matchit(frml, method = 'nearest', data = new_dta,
                        distance = 'glm', link = 'logit')

dta_matched_nn <- match.data(mod_match_nn)

N_ATE<- dta_matched_nn %>% 
  group_by(treat = factor(treat, levels = c(1,0))) %>% 
  summarise(across(where(is.numeric), mean),
            sample_size = n()) %>% 
  select(treat, re78) %>% 
  summarise(ATE = re78 -lead(re78)) %>% 
  drop_na()

kable(N_ATE)
```
#### c) Coarsened exact matching

```{r}

mod_match_cem <- matchit(frml, method = 'cem', data = new_dta,
                         distance = 'glm', link = 'logit', estimand = 'ATE')

dta_matched_cem <- match.data(mod_match_cem, distance = 'pr_score')

CEM_ATE<- dta_matched_cem %>% 
  group_by(treat = factor(treat, levels = c(1,0))) %>% 
  summarise(across(where(is.numeric), mean),
            sample_size = n()) %>% 
  select(treat, re78) %>% 
  summarise(ATE = re78 -lead(re78)) %>% 
  drop_na()
  
kable(CEM_ATE)
```


Recordemos que el efecto causal real usando los datos experimentales es de $1,794. Consideramos que el método de weighting on propensity scores, una vez que se normalizan los datos, tiene el valor más similiar el efecto real causal. Asímismo, el método de VecinosMás cercanos estima resultados similares al valor real. El método de Coarsened Exact Matching estima un resultado mayor al valor real. 


## Bibliografía

- [Causal Inference: The mixtape](https://mixtape.scunning.com/)
- Rajeev H. Dehejia, Sadek Wahba; Propensity Score-Matching Methods for Nonexperimental Causal Studies. The Review of Economics and Statistics 2002; 84 (1): 151–161. doi: https://doi.org/10.1162/003465302317331982



